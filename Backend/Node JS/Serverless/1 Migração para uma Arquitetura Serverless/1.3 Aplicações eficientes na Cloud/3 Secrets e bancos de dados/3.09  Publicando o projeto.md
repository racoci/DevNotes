Já fizemos o _deploy_ para desenvolvimento. Se você seguiu todos os materiais disponibilizados na plataforma para a preparação do ambiente, já terá criado a parte do ambiente de produção também!

Para prosseguir, precisaremos de **uma conta na AWS** e **uma conta no MongoDB Atlas** (ou na _cloud_ do MongoDB), onde hospedaremos nosso banco de dados. Essa ferramenta tem um _tier_ gratuito, então não será muito complicado.

Além disso, será necessário **_salvar a sua connection string no MongoDB em produção_** para podermos fazer a publicação.

## _String_ de conexão

Nossa aplicação já está preparada e pode ser publicada. No navegador, vamos acessar a _dashboard_ do Serverless com o seguinte endereço:

```bash
https://app.serverless.com
```

Nessa página, teremos a lista de nossos _apps_. Vamos clicar no símbolo de três pontos à direita de "alura-activities > api", depois selecionar "_settings_". Na aba "_parameters_", é preciso criar a _connection string_.

Para descobrir a _connection string_, vamos acessar a interface do MongoDB. Na aba "_Database_", clicaremos no botão "_Connect_" à direita do nome do _cluster_. Em seguida, selecionaremos a opção "_Connect with your application_" e teremos a _connection string_ à disposição. Sua estrutura é parecida com a seguinte:

```ruby
mongodb+srv://alura:<password>@cluster0.mgk4ful.mongodb.net/?retryWrites=true&w=majority
```

Perceba que a senha não é exibida na _string_ de conexão. Em vez dela, temos o trecho `<password>`. Você deve adaptá-la conforme a sua senha salva.

Voltando para a _dashboard_, na aba "_parameters_, adicionaremos o parâmetro "connectionsString" com o valor da nossa _string_ de conexão devidamente adaptada e pressionaremos o botão "_Add_".

No VS Code, vamos abrir o arquivo `serverless.yml`. Em `params`, vamos acrescentar a chave `prod` para indicar que temos um ambiente novo de produção e ele não tem parâmetros preenchidos.

## _Deploy_

Após salvar as alterações, executaremos o seguinte comando no terminal:

```lua
sls deploy --stage=prod
```

O arquivo `serverless.yml` será lido e o ambiente de produção será criado. Esse processo pode levar alguns minutos.

**Enquanto esperamos, vamos recapitular o que está acontecendo.** O sistema está recuperando arquivos e os colocando numa pasta chamada ".serverless", que consta na estrutura de arquivos do nosso projeto.

Um arquivo `.zip` da nossa API será criado e enviado para a AWS para a criação de um _cluster_ no CloudFormation, com uma série de instruções para a Amazon gerar os recursos necessários.

Como definimos `--stage=prod`, a variável `connectionString` que definimos em `dev` dentro de `params` não será usada. Em vez disso, pegaremos uma variável que está em produção (`prod`). Como ela não existe ainda, ele selecionará a variável que definimos na _dashboard_ do Serverless há pouco.

Quando criarmos esse ambiente pela primeira vez, ele pegará todas essas variáveis como padrão. Ou seja, estamos assumindo que o Serverless _dashboard_ será nosso ambiente de produção local.

Ao fazer o _deploy_, teremos uma nova chave chamada "prod" na tela inicial da _dashboard_ — trata-se do nosso ambiente. Assim, poderemos testar através dessa publicação.

Uma vez finalizado o _deploy_, serão exibidos no terminal os endereços do POST e do GET publicados em produção. No meu caso, temos as seguintes URLs:

> POST — [https://s7my8uppsa.execute-api.eu-west-1.amazonaws.com/api/results](https://s7my8uppsa.execute-api.eu-west-1.amazonaws.com/api/results)
> 
> GET — [https://s7my8wppsa.execute-api.eu-west-1.amazonaws.com/api/results/{id}](https://s7my8wppsa.execute-api.eu-west-1.amazonaws.com/api/results/%7Bid%7D)

Na _dashboard_, em "alura-activities>api", temos um novo ambiente chamado "prod". Vamos clicar nele. Na nova página, temos uma série de recursos interessantes, pelos quais podemos navegar no menu na parte superior da tela.

Na aba "_overview_", há vários gráficos, como a quantidade de chamadas ou API _requests_. Se você não realizou chamadas anteriormente, esses dados estarão vazios inicialmente. Na aba "_explorer_", podemos explorar algumas chamadas. Na parte inferior dessa seção, é possível verificar dados como a data, o método, o _endpoint_, a duração e o _status_ de requisições. Na aba "_interact_", conseguimos interagir manualmente com nossas APIs. No painel à esquerda, podemos alternar entre "sendResponse" e "getResult", por exemplo.

Nós exploraremos todos esses recursos mais adiante.

## Testes

Para testar, vamos copiar a URL informada no terminal referente ao POST. No VS Code, abriremos a extensão do Thunder Client e selecionaremos uma requisição POST no histórico.

Dessa forma, vamos enviar uma requisição POST para o endereço copiado, com o seguinte objeto:

```json
{
    "name": "Lucas",
    "answers": [1, 2, 3, 4]
}
```

Teremos um resultado semelhante ao seguinte:

> - Status: 201 Created
> - Size: 121 Bytes
> - Time: 2.29 s

```json
{
    "resultId": "63960532dbb99133c01cf8bd",
    "__hypermedia": {
        "href": "/results.html",
        "query": {
            "id": "63960532dbb99133c01cf8bd"
        }
    }
}
```

Note que a resposta demorou um pouco mais que o normal. Esse pequeno atraso ocorre porque, no Serverless, temos um conceito chamado **_Cold Start_**.

Em resumo, quando temos uma função que está parada por algum tempo, todos os recursos que foram alocados para ela serão removidos. Quando reexecutarmos a função, os recursos precisarão ser recriados, por isso pode haver uma pequena demora.

Contudo, se chamarmos essa função com frequência, os recursos não serão destruídos. Como teste, podemos reenviar essa mesma requisição POST e vamos reparar que o tempo será menor!

Vamos continuar nossos testes. Para checar se o novo documento foi devidamente inserido no banco de dados, vamos copiar o ID de uma das respostas e fazer uma requisição GET com a URL informada no terminal e o ID copiado. Por exemplo:

```bash
https://s7my8wppsa.execute-api.eu-west-1.amazonaws.com/api/results/63960532dbb99133c01cf8bd
```

Como resultado, teremos algo semelhante ao seguinte:

> - Status: 200 OK
> - Size: 110 Bytes
> - Time: 2.15 s

```json
{
    "_id": "63960532dbb99133c01cf8bd",
    "name": "Lucas",
    "answers": [
        1,
        2,
        3,
        4
    ],
    "totalCorrectAnswers": 0,
    "totalAnswers": 4
}
```

Na _dashboard_ do Serverless, vamos entrar no ambiente "prod" e acessar a aba "api endpoints". Nos gráficos dessa página, podemos analisar dados das últimas chamadas que fizemos, como a duração e a latência.

Na aba "_interact_", podemos clicar em uma das chamadas que consta na tabela na parte inferior direita para conferir mais detalhes de sua execução.

Na aba "_overview_", temos mais gráficos interessantes para análise. No canto direito superior, é possível selecionar o período de referência para ter uma variabilidade diferenciada. Entre as opções temos: últimos 15 minutos, últimos 60 minutos, últimas 24 horas e últimos 7 dias.

## Em caso de erros

Caso você esteja obtendo erros, recomendamos acessar a aba "_settings_ > _providers_" para se certificar de que há um _provider_ da AWS.

Além disso, em "_settings_ > _access key_", deve existir uma _serverless key_, criada pelo próprio _framework_ em seu primeiro login.

Se você não tiver uma _access key_, você pode abrir o terminal e rodar o seguinte comando para remover um arquivo chamado `serverlessrc`, que fica na sua _home_:

```bash
rm ~/.serverlessrc
```

Em seguida, você deve rodar o comando `sls --org=` seguido do nome da sua organização, para o sistema linkar os dados novamente.

Se você não tiver um _provider_, você pode abrir o terminal e rodar o comando `sls config credentials`, passando o provedor. Contudo, se você tiver removido o arquivo `serverlessrc`, o sistema terá automaticamente feito essa preparação.

Na sequência, vamos entender como deixar essa aplicação mais segura através de autenticação!