**Antonio Evaldo:** Olá! Nesse vídeo, vamos trabalhar com o time do Evaldo e desenvolver a função lambda (`λ`) no _Serverless Framework_.

Para demonstrar melhor como será o fluxo do cadastro de alunos que iremos começar a desenvolver, temos um diagrama com os passos do fluxo:

![Fluxograma de 3 etapas separadas por duas setas azuis horizontais apontando para a direita. As etapas são "Formulário Front-end", "Upload do CSV no Bucket S3", e "1. Processar CSV; 2. Cadastro em batch na API", representadas pelas respectivas ilustrações: um computador conectado a duas pastas abaixo dele; um computador com uma seta saindo da tela apontando para cima em direção a uma nuvem; e um sinal de lambda. Acima da segunda seta, a inscrição "gatilho (trigger)".](https://cdn1.gnarususercontent.com.br/1/1310271/8d31bfd7-583e-4570-ac5a-4470428183a5.png)

1. O primeiro passo do fluxo é o **formulário de front-end**, conforme visto no vídeo de apresentação do curso;
2. O segundo passo é fazer o **upload do arquivo CSV no Bucket S3**;
3. No terceiro passo, assim que o upload do CSV for feito, será gerado um gatilho (chamado de _trigger_ em inglês) para executar a função lambda. Ela fará duas tarefas principais: processar o CSV, e em seguida realizar o **cadastro em _batch_** (ou em lote) **na API**.

Trazemos esse fluxo para facilitar o entendimento, pois não é tão trivial identificar em qual etapa do processo nós estamos.

**Por exemplo:** para que o formulário de front-end consiga realizar o upload do CSV no bucket, primeiro o bucket precisa existir na sua conta da AWS. Ainda faremos isso com o Serverless Framework.

> O slide com o fluxograma ficará disponibilizado em uma atividade para futuras consultas, caso você tenha dúvidas sobre o processo.

Então começaremos a desenvolver a segunda etapa em conjunto com a terceira. Vamos simular ambos os passos **localmente**.

Em geral, trabalhamos dessa forma: começamos com um código local, preparamos esse código para produção, e depois fazemos o _deploy_.

Você deve estar se perguntando: como simular localmente um Bucket S3, um serviço da AWS hospedado em nuvem? Veremos o passo a passo.

## Criando o projeto _Serverless_

Nossa primeira etapa será criar um projeto em Serverless. Vamos manter o dashboard aberto e acessar o terminal _Ubuntu_.

> No Windows, utilizamos o WSL. A instrutora Ju deixou preparado como instalar, caso você também utilize o Windows. Após a instalação, o terminal Ubuntu estará disponível.

Primeiro precisamos nos assegurar de que pelo menos a versão 18 do Node.js esteja no computador. Também há uma atividade explicando como fazer isso.

Para verificar, digitamos o seguinte comando no terminal:

```undefined
node -v
```

No meu caso, está instalada a versão "v18.15.0".

Além disso, o Serverless Framework também está instalado no meu computador. Para verificar a versão, podemos digitar um dos comandos abaixo:

```undefined
sls -v
```

```undefined
serverless -v
```

No meu caso, é retornado o seguinte resultado, indicando a versão "3.29.0":

```yaml
Framework Core: 3.29.0
Plugin: 6.2.3
SDK: 4.3.2
```

> Na atividade anterior, também é explicado como verificar as versões corretas e quais são compatíveis. Qualquer tipo de versão 3 do Serverless funcionará normalmente.

Preparado o nosso ambiente, vamos criar o projeto Serverless. Podemos criá-lo em qualquer pasta desejada. Criarei em uma pasta criada de antemão, chamada "projetos". Para acessá-la, utilizamos o comando `cd`:

```bash
cd projetos
```

Feito isso, vamos executar o comando `sls` ou o comando `serverless` após `~/projetos$`, conforme mencionado anteriormente.

Com esses comandos, a CLI do Serverless Framework vai interagir conosco e perguntar como queremos criar o projeto:

```vbnet
Creating a new serverless project

? What do you want to make? (Use arrow keys)
  AWS - Node.js - Starter
  AWS - Node.js - HTTP API
  AWS - Node.js - Scheduled Task
  AWS - Node.js - SQS Worker
  AWS - Node.js - Express API
  AWS - Node.js - Express API with DynamoDB
  AWS - Python - Starter
  AWS - Python - HTTP API
  AWS - Python - Scheduled Task
  AWS - Python - SQS Worker
  AWS - Python - Express API
  AWS - Python - Express API with DynamoDB
  Other
```

Utilizando as setas para cima e para baixo do teclado, vamos selecionar a segunda opção que consiste em um projeto **HTTP API**.

Teclamos "Enter" para finalizar a ação. Feito isso, temos como resposta no terminal o tipo de projeto selecionado, e uma pergunta sobre qual nome queremos dar ao projeto. Vamos chamá-lo de `serverless-framework-2-lambda`.

> O "2" corresponde ao segundo curso da formação. Já o "lambda" ao final é utilizado para evidenciar que o projeto se refere à função lambda.

```vbnet
? What do you want to make? AWS - Node.js - HTTP API
? What do you want to call this project? serverless-framework-2-lambda
```

Para confirmar, teclamos "Enter" novamente. Em seguida, o terminal irá perguntar se queremos utilizar credenciais da AWS, pois elas não foram encontradas.

```perl
? No AWS credentials found, what credentials do you want to use? (Use arrow keys)
  Local AWS Access Keys
  Skip
```

Se você já tem as suas credenciais configuradas na sua conta da AWS, essa pergunta não será retornada. Caso contrário, ainda é necessário configurá-las. Para isso, selecionamos a opção `Local AWS Access Keys` com "Enter".

Será retornada a pergunta `Do you have an AWS account? (Y/n)` (em português, `Você tem uma conta AWS? (Sim/não)`). Diremos que sim digitando apenas `Y` e teclando "Enter".

Será aberta uma página no navegador para criar uma chave de acesso. Caso você não tenha feito isso, a Ju ensinou o processo na aula 1.

No meu caso, não irei utilizá-la, pois ela a chave de acesso já foi criada. Então vamos retornar ao terminal e utilizar suas informações.

```vbnet
? In your AWS account, create an AWS user with access key. Then press [Enter] to continue.

? AWS Access Key Id: <KEY ID>
```

> **Observação:** no terminal Ubuntu, não utilizamos o atalho "Ctrl + V" para colar a informação copiada, e sim o botão direito.

Você pode usar a mesma chave de acesso utilizada na aula 1. Se por algum motivo não tiver mais acesso à sua chave, crie uma nova na sua conta da AWS e insira no terminal.

> A chave utilizada acima é diferente da chave utilizada pela Ju na aula 1. Porém, isso não é um problema, pois já fizemos uma configuração prévia para que, mesmo utilizando chaves diferentes, tenhamos o mesmo acesso aos recursos da AWS, como o Bucket S3.

Após inserir a chave de acesso, vamos copiar a chave de acesso secreta, colar no terminal e teclar "Enter" novamente para confirmar.

```vbnet
? AWS Access Key Id: <KEY ID>
? AWS Secret Access Key: <ACCESS KEY>

  AWS credentials saved on your machine at "~/.aws/credentials". Go there to change them at any time.

? Do you want to deploy now? (Y/n)
```

Conforme indicado acima, o terminal informa que as credenciais foram salvas na máquina em um caminho específico ("/.aws/credentials").

Por fim, somos perguntados se queremos ou não fazer o deploy da aplicação. Nesse momento, vamos responder "Não", ou seja, `N`, pois queremos testar primeiro de forma local.

Agora que nosso projeto foi criado com sucesso, vamos entrar na pasta correspondente (`serverless-framework-2-lambda`) utilizando o comando `cd`. Após teclar "Enter", temos o seguinte resultado no terminal:

```bash
~/projetos$ cd serverless-framework-2-lambda
~/projetos/serverless-framework-2-lambda$
```

Em seguida, vamos abrir a pasta do projeto com o comando `code .`.

```css
code .
```

Teclando "Enter" para confirmar, o VS Code será aberto diretamente na pasta do projeto.

> **Observação:** o meu VS Code já está configurado com a extensão WSL. Se você utiliza o Windows, também é necessário fazer essa configuração, para um melhor _IntelliSense_ do programa.
> 
> Falamos sobre isso na atividade "Preparando o ambiente", então caso tenha dificuldades, basta segui-la.

Vamos analisar o projeto criado para nós. Você já deve conhecê-lo do projeto inicial do curso anterior na formação.

Temos um arquivo `index.js`, que exporta uma função chamada `handler`.

```js
module.exports.handler = async (event) => {
  return {
    statusCode: 200,
    body: JSON.stringify(
      {
        message: "Go Serverless v3.0! Your function executed successfully!",
        input: event,
      },
      null,
      2
    ),
  };
};
```

Também temos o arquivo `serverless.yml`. Ele traz algumas configurações, como o nome do serviço (`service`), a versão do framework (`frameworkVersion`), o `provider`, e as `functions`.

```yml
service: serverless-framework-2-lambda
frameworkVersion: '3'

provider:
  name: aws
  runtime: nodejs18.x

functions:
  api:
    handler: index.handler
    events:
      - httpApi:
          path: /
          method: get
```

Em `functions`, está especificada uma função chamada `api` e algumas configurações, como o caminho dela, por exemplo, que é justamente no arquivo `index` com a função `handler`. Por fim, temos alguns eventos.

Essa função está configurada para reagir a uma **requisição HTTP**, conforme aprendemos no curso anterior da formação.

Agora queremos fazer uma função `lambda` que reaja a um evento do S3. Vamos começar a experimentar nesse arquivo.

Nosso primeiro passo será renomear o nome da função de `api` para `cadastrarAlunos`, já que esse será o intuito final da função.

Além disso, vamos alterar a informação de `index.handler` para `index.cadastrarAlunos`.

```yml
# Código suprimido

functions:
  cadastrarAlunos:
    handler: index.cadastrarAlunos
    events:
      - httpApi:
          path: /
          method: get
```

Em seguida, vamos retornar ao arquivo `index.js` e alterar o nome da função `handler` para `cadastrarAlunos`.

```js
module.exports.cadastrarAlunos = async (event) => {

/* Código suprimido */
```

Retornando ao arquivo `serverless.yml`, vamos ajustar a propriedade `events`. Há um item de lista (`-`) do YML chamado `httpApi`. Vamos apagar esse trecho do código e escrever apenas `- s3`.

> É importante que o "s" esteja minúsculo!

```yml
# Código suprimido

functions:
  cadastrarAlunos:
    handler: index.cadastrarAlunos
    events:
      - s3:
```

Feito isso, vamos digitar dois-pontos, teclar "Enter" e adicionar quatro espaços na linha seguinte, logo após o hífen (`-`) que representa o início da lista. Essa indentação é muito importante!

Após a indentação, vamos incluir a propriedade `bucket`, contendo o nome do bucket que iremos utilizar para armazenar arquivos. O nome será `alunos-csv-local`.

> Conforme dito anteriormente, começaremos trabalhando de forma local, então utilizanod `local` no nome da propriedade. Depois veremos como interagir com o Bucket S3 local.

```yml
# Código suprimido

functions:
  cadastrarAlunos:
    handler: index.cadastrarAlunos
    events:
      - s3:
          bucket: alunos-csv-local
```

Vamos adicionar uma segunda propriedade, chamada `event`. Após os dois-pontos, vamos adicionar `s3:ObjectCreated:*`.

> É necessário que você escreva da mesma forma exibida acima, com o "O" e o "C" maiúsculos, enquanto o "s" de `s3` permanece minúsculo.

```yml
# Código suprimido

functions:
  cadastrarAlunos:
    handler: index.cadastrarAlunos
    events:
      - s3:
          bucket: alunos-csv-local
          event: s3:ObjectCreated:*
```

Esse `event` significa que a função `cadastrarAlunos` irá reagir ao evento `ObjectCreated`, especificado pela própria AWS.

O asterisco (`*`) indica que existem algumas operações relacionadas ao `ObjectCreated`, mais especificamente a alguns métodos utilizados pela AWS.

**Por exemplo:** se removêssemos o asterisco, poderíamos digitar POST ou PUT, exemplos de métodos da AWS que estão relacionados ao evento `ObjectCreated`.

A partir do momento em que utilizamos um asterisco em vez de um método específico, indicamos que a nossa função irá reagir a qualquer um desses métodos, independentemente de qual seja.

Para fechar o evento do `s3`, vamos escrever uma nova propriedade chamada `rules` (em português, "regras"). Nesse caso, após os dois-pontos vamos adicionar um item de lista chamado `suffix`. Dentro dele, vamos escrever apenas `.csv`.

```yml
# Código suprimido

functions:
  cadastrarAlunos:
    handler: index.cadastrarAlunos
    events:
      - s3:
          bucket: alunos-csv-local
          event: s3:ObjectCreated:*
          rules:
            - suffix: .csv
```

Com isso, indicamos que a nossa função deverá reagir apenas a arquivos de extensão `.csv`. Assim, refinamos como a nossa função irá reagir ao evento de `s3`, fazendo o upload de um arquivo CSV.

## Conclusão

Esse é o primeiro passo para começar a configurar uma função lambda que interaja com o Bucket S3. No próximo vídeo, vamos aprender a configurar o Bucket S3 de forma local e verificar se a função funciona corretamente.

**Te espero lá!**