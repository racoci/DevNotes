**Antonio Evaldo:** Nós já criamos o projeto em Serverless Framework e começamos a configurar a função que vai reagir ao Bucket S3. Daremos continuidade ao processo nesse vídeo.

## Simulando um servidor S3 local

Primeiro, precisamos simular um Bucket S3 de forma local. Para fazer isso, serão necessários alguns plugins do Serverless Framework.

Para instalá-los, vamos abrir o terminal integrado no VS Code utilizando o atalho "Ctrl + J". Digitaremos o comando `sls plugin install`.

Em seguida, digitamos `--name` para incluir o nome do plugin, que será "serverless-offline@12.0.4".

> Já conhecemos esse plugin no curso anterior. Iremos instalar a versão 12.0.4 para que você fique em congruência comigo ao longo do processo.

```css
sls plugin install --name serverless-offline@12.0.4
```

Ao teclar "Enter" no comando, o plugin começará a ser instalado no projeto de forma local, conforme desejado.

O plugin "serverless-offline@12.0.4" serve para testar funções de forma local, principalmente funções que reagem a requisições HTTP.

Porém, vamos simular um Bucket S3 local, então precisaremos instalar outros plugins. Enquanto o plugin acima é instalado, vamos adicioná-lo ao arquivo `serverless.yml`.

Começaremos adicionando a propriedade `plugins`. Na linha abaixo, daremos dois espaços e colocaremos um item de lista chamado `serverless-offline`. Assim, indicamos que nosso projeto precisa utilizar esse plugin específico.

```yml
service: serverless-framework-2-lambda
frameworkVersion: '3'

provider:
  name: aws
  runtime: nodejs18.x

functions:
  cadastrarAlunos:
    handler: index.cadastrarAlunos
    events:
      - s3:
          bucket: alunos-csv-local
          event: s3:ObjectCreated:*
          rules:
            - suffix: .csv

plugins:
  - serverless-offline
```

Agora vamos instalar o segundo plugin. No terminal integrado, utilizaremos o mesmo comando `sls plugin install`, seguido de `--name` e do nome do plugin, que agora será a versão "serverless-s3-local@0.7.1".

```css
sls plugin install --name serverless-s3-local@0.7.1
```

Esse plugin utiliza uma biblioteca do Node.js chamada **S3RVER**, cujo nome é uma brincadeira com "server" e "S3".

Ele será responsável por criar um servidor S3 para nós, mas antes iremos testá-lo para entender como funciona na prática.

Para utilizá-lo no projeto, vamos adicionar mais um item na lista de plugins, chamado `serverless-s3-local`.

```yml
plugins:
  - serverless-offline
  - serverless-s3-local
```

Feito isso, podemos salvar o arquivo e tentar testar localmente o Bucket S3. No terminal integrado, podemos digitar tanto o comando `serverless offline` quanto `sls offline`:

```undefined
sls offline
```

```undefined
serverless offline
```

Perceba ser o mesmo comando que utilizamos para o plugin `serverless-offline`, pois o plugin `serverless-s3-local` foi feito para funcionar em conjunto com outro plugin de `serverless-offline`.

Após confirmar a ação, teremos os seguintes retornos:

```less
Found S3 event listener for alunos-csv-local
S3 local started ( port:4569, family: IPv4, address: 127.0.0.1 )
```

A primeira mensagem diz que foi encontrado um ouvinte de evento de S3 para "alunos-csv-local". Essa mensagem aparece porque já configuramos a função `cadastrarAlunos` que reage a um evento do S3.

Então o plugin identifica essa função no arquivo `serverless.yml`.

Em seguida, temos a mensagem de que o S3 local foi inicializado na porta 4569, junto a outras informações de servidor, como família e endereço.

> Atualmente, no momento em que executamos o comando, já existe um servidor S3 sendo executado localmente e poderemos interagir com ele. Faremos isso em breve.

Perceba que após a execução do comando `sls offline`, foi criada uma pasta chamada "**buckets**" na raiz do projeto. Ao abri-la, encontraremos outra pasta chamada "**alunos-csv-local**".

Essas pastas representam um Bucket S3 real da AWS. É dessa forma que o testaremos de forma local.

Da mesma forma que um bucket da S3 armazena arquivos, a pasta "buckets" também irá armazenar, mas localmente, de modo que seja possível interagir com ela.

Para interagir com o servidor, precisamos executar um código de forma arbitrária. Então vamos configurar mais uma função no arquivo `serverless.yml`, a qual irá reagir a um **evento HTTP**. Dessa forma, conseguiremos simular a interação com o Bucket S3.

Logo antes da função `cadastrarAlunos`, vamos configurar a função `simulandoUploadDoCsv`, pois esse será seu propósito final.

```yml
# Código suprimido

functions:
  simulandoUploadDoCsv:

  cadastrarAlunos:
    handler: index.cadastrarAlunos
    events:
      - s3:
          bucket: alunos-csv-local
          event: s3:ObjectCreated:*
          rules:
            - suffix: .csv
```

Ela terá uma propriedade chamada `handler`, cujo caminho será `index.simulandoUploadDoCsv`.

```yml
# Código suprimido

functions:
  simulandoUploadDoCsv:
    handler: index.simulandoUploadDoCsv

# Código suprimido
```

Logo abaixo, teremos a propriedade `events`, contendo uma lista de itens chamada `httpApi`. A lista, por sua vez, terá algumas propriedades.

A primeira propriedade será escrita na próxima linha, garantindo os 4 espaçamentos a partir do hífen (`-`). O nome da propriedade é `path`, correspondente ao caminho da requisição HTTP que deve ser feita.

O caminho será `/alunos/batch`, lembrando que "batch" se refere ao cadastro em lote.

A segunda propriedade irá se chamar `method`, que será definida como `post`.

```yml
# Código suprimido

functions:
  simulandoUploadDoCsv:
    handler: index.simulandoUploadDoCsv
    events:
      - httpApi:
          path: /alunos/batch
          method: post

# Código suprimido
```

Dessa forma, conseguimos simular uma requisição HTTP localmente. A pretensão com essa função é que, ao executá-la, seja possível interagir com o bucket local.

Para visualizar melhor como isso acontece, vamos retornar ao arquivo `index.js` e criar essa função na primeira linha de código.

Começaremos com `module.exports`, seguido de um ponto e do nome da função `simulandoUploadDoCsv`. Ela irá receber uma função assíncrona (`async`), a qual recebe `evento` como parâmetro.

Para finalizar, criamos uma _arrow function_ utilizando `=>`.

```js
module.exports.simulandoUploadDoCsv = async (evento) => {

}

module.exports.cadastrarAlunos = async (event) => {
  return {
    statusCode: 200,
    body: JSON.stringify(
      {
        message: "Go Serverless v3.0! Your function executed successfully!",
        input: event,
      },
      null,
      2
    ),
  };
};
```

Como essa é uma função lambda que reage a uma requisição HTTP, basicamente iremos receber um evento com algumas propriedades que já conhecemos. Além disso, precisamos retornar um objeto com propriedades específicas.

Primeiro, vamos adicionar um bloco **try…catch**. No `catch`, receberemos `erro` como parâmetro, para evitar qualquer erro de execução.

No bloco `try`, vamos escrever o método `console.log()` e colocar entre parênteses a frase "Simule aqui o upload do arquivo…".

> A frase será substituída posteriormente pela real operação de interação com o Bucket S3. Por enquanto, vamos manter esse método `console.log()` e testar se a função é executada corretamente ao fazer a requisição HTTP.

```js
module.exports.simulandoUploadDoCsv = async (evento) => {
  try {
    console.log("Simule aqui o upload do arquivo…");

  } catch (erro) {

  }
}

/* Código suprimido */
```

Após o método `console.log()`, vamos utilizar o `return` para retornar um objeto cuja propriedade é `statusCode`, com o valor `200`.

```js
module.exports.simulandoUploadDoCsv = async (evento) => {
  try {
    console.log("Simule aqui o upload do arquivo…");

    return {
      statusCode: 200,
    };
  } catch (erro) {

  }
}

/* Código suprimido */
```

Além de `statusCode`, há mais uma propriedade chamada `body`, cujo valor é o método `JSON.stringify()`.

Ele receberá como parâmetro um objeto com a propriedade `mensagem`, que irá se chamar "Simulando upload de arquivo…".

> Perceba que estamos organizando de forma semântica o que será feito em cada etapa das funções.

```js
module.exports.simulandoUploadDoCsv = async (evento) => {
  try {
    console.log("Simule aqui o upload do arquivo…");

    return {
      statusCode: 200,
      body: JSON. stringify({
        mensagem: "Simulando upload de arquivo…"
      })
    };
  } catch (erro) {

  }
}

/* Código suprimido */
```

Por fim, vamos copiar o `return` que acabamos de escrever e colar dentro do `catch` do erro. Vamos reaproveitar o código e fazer algumas alterações.

Onde está o valor `200`, vamos escrever `erro.statusCode` seguido de duas barras verticais (`||`). Com isso, indicamos que se o `statusCode` não existir, será passado o `statusCode` genérico `500`.

Na propriedade `body`, vamos alterar o conteúdo do método `JSON.stringify()`. Após apagar o objeto, vamos passar apenas `erro` como parâmetro.

```js
module.exports.simulandoUploadDoCsv = async (evento) => {
  try {
    console.log("Simule aqui o upload do arquivo…");

    return {
      statusCode: 200,
      body: JSON. stringify({
        mensagem: "Simulando upload de arquivo…"
      })
    };
  } catch (erro) {
    return {
      statusCode: erro.statusCode || 500,
      body: JSON. stringify(erro)
    };
  }
}

/* Código suprimido */
```

Feito isso, podemos salvar o arquivo. Agora vamos abrir o terminal integrado, encerrar o servidor que estava sendo executado, e executá-lo novamente com o mesmo comando:

```undefined
sls offline
```

Será retornado o seguinte:

```bash
Found S3 event listener for alunos-csv-local
warn: the bucket "alunos-csv-local" already exists
S3 local started ( port:4569, family: IPv4, address: 127.0.0.1 )

Starting Offline at stage dev (us-east-1)

Offline [http for lambda] listening on http://localhost:3002
Function names exposed for local invocation by aws-sdk:
           * simulandoUploadDoCsv: serverless-framework-2-lambda-dev-simulandoUploadDoCsv
           * cadastrarAlunos: serverless-framework-2-lambda-dev-cadastrarAlunos

POST | http://localhost:3000/alunos/batch
POST | http://localhost:3000/2015-03-31/functions/simulandoUploadDoCsv/invocations
```

O terminal indica que existe a rota "/alunos/batch" disponível para fazer uma requisição **POST**. Era isso que queríamos, pois assim poderemos executar o código com o método `console.log()`.

Além disso, o servidor identificou que a função `cadastrarAlunos` está sendo declarada, porém, não existe uma rota disponível para ela. Afinal, ela reage apenas a um evento do S3, e não a uma requisição HTTP.

Ou seja, foi identificado que a função existe, mas ela não tem uma rota própria.

Podemos fechar o terminal integrado. Agora vamos abrir a extensão _Thunder Client_, localizada no menu lateral esquerdo do VS Code. Também podemos utilizar o atalho "Ctrl + Shift + R".

> As instruções para baixar a extensão também estão disponibilizadas na atividade "Preparando o ambiente".

Com ela aberta, vamos clicar no botão "_New Request_" ("Nova Requisição"). Na barra de endereço, vamos escrever o mesmo endereço exibido no terminal integrado:

```bash
http://localhost:3000/alunos/batch
```

Conforme indicado no terminal, o método é **POST**, então vamos selecioná-lo no menu suspenso à esquerda da barra de endereço. Feito isso, podemos clicar no botão "_Send_".

Teremos como retorno o status "**200 OK**" e a mensagem abaixo:

```json
{
  "mensagem": "Simulando upload de arquivo…"
}
```

Após isso, se abrirmos o terminal integrado, teremos o seguinte retorno:

```bash
POST /alunos/batch (λ: simulandoUploadDoCsv)
Simule aqui o upload do arquivo…
(λ: simulandoUploadDoCsv) RequestId: # ID omitido
```

Segundo o terminal, foi executada a função lambda simulando o upload do CSV. Sabemos então que a função HTTP foi executada.

## Conclusão

No próximo vídeo, vamos integrar as duas partes. Iremos escrever um código na função que reaja a um evento HTTP para interagir com o Bucket S3 local, um servidor que já sabemos estar de pé. Ao interagir, vamos avaliar se nossa função lambda reage de acordo.

**Te espero lá!**