**Ju Amoasei:** Neste vídeo, vamos entender como o Serverless vai nos ajudar a implantar essa nova funcionalidade!

Vamos pensar novamente na nossa API base. Como ela está funcionando?

Você, que vai trabalhar com o Evaldo fazendo o Serverless, não precisa entender a fundo como a API está funcionando porque a API está com outro time, você só está recebendo a URL, etc. Mas, pensando um pouco no que vimos até agora, nossa API tem a rota `/alunos`, podemos usar o método POST para pegar um input da tela e chamar o método `cadastrarAluno()` recebendo os dados do aluno.

Então, ela faz isso a cada registro.

No caso do arquivo CSV, poderíamos pensar assim: só precisamos fazer a API receber o arquivo, criar um método extra para processar esse arquivo e, depois que o arquivo é processado, chamar a função `cadastrarAluno()`.

Mas, vamos analisar quais são as implicações de reutilizarmos a API que já está no ar e fazer essa inserção nela.

Atualmente, a API está rodando em uma máquina virtual na qual ela está sempre disponível. Ou seja, essa API tem recursos da AWS que estão locados para que ela use permanentemente. Porque os times comerciais que trabalham conosco estão sempre adicionando novos alunos na plataforma.

Como vimos anteriormente no curso de Serverless, uma máquina virtual que está sempre disponível gera custo. Ela está sempre online mesmo que não esteja recebendo requisições, ela nunca desliga, mesmo que seja final de semana, feriado, etc.

A máquina virtual é um computador, tem recursos de CPU, recursos de RAM, que são finitos. Costumamos dizer que a nuvem nada mais é do que o computador de outra pessoa.

Precisamos sempre ter em mente que ela tem custo. O que nós estamos trabalhando é sempre o mesmo tipo de requisição, conseguimos calcular mais ou menos os custos e recursos necessários para essa API. Quando falo recurso, eu penso em recurso de RAM, recurso de CPU, etc.

Quando falamos de processamento de arquivo, não sabemos muito bem qual é o tamanho do arquivo que vai chegar e qual a quantidade de linhas que esse arquivo vai ter. Então, pode ser tanto um CSV com 10 mil linhas quanto um CSV com 1 milhão de linhas, por exemplo, se for uma empresa muito grande.

Então, não temos muito como saber quanto vai custar para deixar isso sempre no ar sem saber os recursos que vai alocar. Isso envolve uma série de configurações extras porque não temos como saber antecipadamente quanto de RAM e de CPU isso vai gastar.

Então, seria legal passar a responsabilidade do processamento desse arquivo da API para um outro serviço. E esse serviço não precisa ficar sempre online, porque não temos tanto volume de uso. As contas de empresa da nossa plataforma de cursos são poucas, não é sempre que esse serviço de cadastrar via CSV precisa ser utilizado.

Você já deve ter percebido que seria muito melhor ter uma forma de desligar essa API quando ela não estiver sendo utilizada. Uma forma de ligá-la apenas quando ela for chamada e ter custos baseados na quantidade de processamento que ela fizer.

## Função Lambda

Para isso, usaremos o Serverless. É uma boa opção porque conseguimos desligar, fazer a chamada da função somente quando ela é necessária e o processamento de uma função Lambda é feito em máquinas compartilhadas com diversas outras máquinas na AWS. O AWS no caso é o nosso provedor de serviços. Ele utiliza toda a estrutura dele quando precisa processar uma função Lambda.

Então, em vez de usarmos nossa própria infraestrutura, utilizaremos a infraestrutura da AWS.

Dessa forma, não teremos problemas caso tenhamos um arquivo CSV muito grande ou caso precisemos de mais processamento. Porque a AWS vai se encarregar de fazer esse cálculo para nós e usar o processamento necessário.

Além disso, não teremos custo fixo de servidor porque o custo é baseado na execução e no tempo. O cálculo é baseado em quantas vezes a função é executada, o tempo que ela é utilizada e quanto de memória é alocada para esse processamento.

As funções Lambda têm algumas limitações que são colocadas pela própria AWS, por exemplo, elas têm um tempo de execução máxima de 15 minutos, o que para o nosso caso é mais do que suficiente.

E também não teremos o problema de _cold start_, que é aquele tempo inicial que leva para a Amazon ligar a infraestrutura da função, porque esse é o tipo de coisa que o usuário já espera um processamento mais demorado. Podemos usar recursos de UX, por exemplo, um _spinner_ na tela para que o usuário não se surpreenda se a função demorar um pouco para ser processada.

## Resumo

Nosso serviço auxiliar de cadastro em lote (_batch_) vai se plugar ao serviço principal de cadastro, que é a API que colocamos no ar, através de uma função Lambda do Serverless que o Evaldo vai fazer com você.

Existem outras formas de implementar essa funcionalidade, escolhemos o Serverless por questões de custo, performance e para separação de responsabilidade. Assim deixaremos a Lambda separada da API principal porque elas têm responsabilidades diferentes.

E, ao invés de ser um serviço Serverless que se comunica através do HTTP, como fizemos no curso anterior, veremos como fazer essa comunicação da função Lambda com a HTTP e faremos essa comunicação de forma que da função Lambda comunique-se direto com a API sem precisar de um gatilho HTTP.

A partir da próxima aula, você vai aprender com o Evaldo como implementar essa função Lambda e colocar tudo no ar!