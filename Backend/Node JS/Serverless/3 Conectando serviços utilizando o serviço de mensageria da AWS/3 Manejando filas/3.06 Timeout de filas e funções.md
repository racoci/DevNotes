# 3.06 Timeout de filas e funções

Anteriormente, criamos uma fila DLQ para receber as mensagens "perdidas". Vamos entender como o SQS e o Serverless manejam estas situações juntos.

O que ocorre quando uma mensagem é transferida para a DLQ? Algumas configurações de fila influenciam a maneira com que o _Lambda_, o SQS e o Serverless manejam as filas e suas mensagens:

- Timeout
- Batch (lote)
- Concurrency (concorrência)

Tanto as filas no SQS quanto as funções possuem configurações de _Timeout_ próprias que agem em conjunto.

Em relação aos _batches_, não entraremos em detalhes sobre a forma com que o SQS trabalha com elas. Em vez disso, disponibilizaremos materiais sobre esse assunto nas atividades da aula.

Anteriormente, havíamos adicionado um `batchSize` com o valor `1` no `CadastroConsumer`. Isso significa que cada lote de mensagens terá apenas uma mensagem.

```yaml
cadastroConsumer:
  handler: src/functions/consumers/cadastroConsumer.cadastroConsumer
  events:
    sqs:
      arn:
        Fn::GetAtt:
          - FilaCadastro
          - Arn
      batchSize: 1
```

O SQS pode trabalhar com lotes de mensagens. Ele possui uma quantidade mínima de 1 mensagem e sua quantidade máxima varia de 10000 para filas standard e 10 para filas FIFO. Podemos pedir que ocorra o processamento a cada 10 mensagens, por exemplo.

No caso do nosso produto, concluímos que é mais interessante trabalhar com 1 mensagem por vez e 1 `aluno` por mensagem.

Será que teremos muitas mensagens? Devemos entender que alguns milhares de mensagens não são considerados grandes quantidades para o SQS. Não acreditamos que haverão muitas ocorrências maiores do que isso em nosso produto atual.

Nos casos de outros produtos, pode ser interessante trabalharmos com lotes de mensagens.

O conceito de _concurrency_ pode ser aplicado de várias maneiras no universo da programação. No nosso contexto, ele se referirá à quantidade de instâncias de uma _lambda_ que poderão ser executadas simultaneamente.

Considerando o `cadastroConsumer`, ele nos indica quantas vezes ele poderá ser executado em paralelo. Se houver uma quantidade grande de mensagens para processar, por exemplo, ele definirá quantas funções `cadastroConsumer` (ou outra qualquer) poderão ser chamadas.

Em nosso produto, quando pensamos em concorrência, devemos considerar que se adicionamos muitas instâncias de funções que enviam mensagens para API em paralelo, teremos a mesma quantidade de requisições paralelas para a API REST. Neste caso, precisamos saber quantas requisições simultâneas são suportadas pela API REST.

Portanto, quando trabalhamos com serviços separados que se comunicarão e enviarão requisições para outro lado da aplicação, precisamos considerar a quantidade de chamadas que serão efetuadas ao serviço. Caso contrário, podemos derrubar uma parte do serviço ou API involuntariamente.

Neste momento, não configuraremos a concorrência para possuir diversas instâncias, mas precisamos ponderar sobre este tipo de situação.

Voltando ao VSC, no arquivo `serverless.yaml`, configuramos a propriedade `VisibilityTimeout` com o valor `10`. Vamos entender esse número configurado.

_**Quanto tempo de `VisibilityTimeout` adicionamos em uma fila?**_

Essa propriedade se refere ao tempo em segundos que uma mensagem ficará "escondida" antes de ser adicionada novamente na fila. Vamos ver isso com mais calma.

O processamento de uma mensagem ocorre da seguinte forma: enquanto a mensagem está sendo enviada, o SQS "esconde" a mensagem da fila e ela se torna indisponível para que ela não seja chamada novamente. Esse tempo de ocultamento é chamado de _visibility timeout_ (limite de visibilidade).

Estamos utilizando as filas FIFO para barrar duplicidades por meio do recurso de ID de duplicação, que organiza e compara mensagens. Além dele, utilizaremos o recurso de _Timeout_, orquestrando o tempo de invisibilidade entre a função que chama a fila e as mensagens desta.

Vamos verificar como isso funcionará do outro lado, na fila. Desceremos o arquivo atual, voltando até a seção `cadastroConsumer`. Por enquanto ele não possui nenhum valor de _timeout_.

Como descobrimos quanto tempo uma mensagem leva para ser executada? Por meio do console do Serverless.

Vamos acessá-lo por meio do navegador, clicar na guia "_explorer_" e na guia secundária "_invocations_", abaixo dela. No corpo da página desceremos a tela até a tabela de _invocations_, e buscaremos as chamadas de `cadastroConsumer`.

|**Timestamp**|function|**duration**|memory|cold start|errors|
|---|---|---|---|---|---|
|…|…|…|…|…|…|
|06/07 14:53:54.101|cadastroConsumer|184 ms|97 mb (9%)|254 ms|TypeError|
|06/06 16:42:32.735|cadastroConsumer|30 ms|104 mb (10%)|0 ms|none|
|06/06 16:42:32.654|cadastroConsumer|47 ms|102 mb (10%)|0 ms|none|
|06/06 16:42:32.387|cadastroConsumer|200 ms|92 mb (9%)|245 ms|none|
|…|…|…|…|…|…|
|06/06 16:12:37.737|cadastroConsumer|25 ms|114 mb (11%)|0 ms|none|
|…|…|…|…|…|…|

Nessa tabela, veremos que existe a coluna "_durations_"referente ao tempo que a função levou para ser executada, em milissegundos. A nossas funções `cadastroConsumer` levam tempos variados para serem executadas.

Alinhada à direita, temos a coluna "_cold start_", recurso do Serverless que desliga a infraestrutura por trás da função se ela passar muito tempo sem ser chamada. Quando ocorre novamente a chamada, ela demorará mais para ser processada, já que a infra deverá ser subida novamente.

As chamadas de funções onde o _cold start_ ocorreu estão sinalizadas no console. A chamada `cadastroConsumer` demora em torno de 245 milissegundos para acontecer nas chamadas realizadas em _cold start_.

Com isso, vemos que a função `cadastroConsumer` não leva mais de um segundo para ser processada, até mesmo por se tratar de um código curto. Para deixar uma folga, configuraremos em `2` segundos.

Voltando ao arquivo YAML no VSC, dentro da função `cadastroConsumer`, abaixo da linha `batchSize`, adicionaremos um tempo de processamento (`timeout`) com o valor `2`. Este atributo deve ser incluso na mesma hierarquia de alinhamento do `events`.

```yaml
cadastroConsumer:
  handler: src/functions/consumers/cadastroConsumer.cadastroConsumer
  events:
    sqs:
      arn:
        Fn::GetAtt:
          - FilaCadastro
          - Arn
      batchSize: 1
    timeout: 2
```

Em relação ao `VisibilityTimeout` da fila associada a `cadastroConsumer`, como chegamos no valor `10`? Vamos realizar o seguinte raciocínio: se uma aplicação leva 10 segundos para processar e deixamos um `timeout` configurado na fila para 15 minutos (o que é possível), teremos que aguardar 15 minutos para que uma mensagem seja processada novamente nos casos de problemas na primeira tentativa. Não precisamos esperar tanto tempo.

Por outro lado, se uma função leva 10 segundos para processar e ajustarmos o `VisibilityTimeout` da fila para 2 segundos, a mensagem se tornará disponível antes da função finalizar o processamento original. Isso pode gerar problemas de duplicidade.

A AWS (e não o SQS) reforça como regra que o tamanho do `VisibilityTimeout` de uma fila deve ser em torno de 5 a 6 vezes maior do que o tempo o que o `timeout` da função. Neste caso, se adicionamos um `timeout` de 2 segundos para `cadastroConsumer`, podemos configurar o `VisibilityTimeout` da fila com um valor entre 10 e 12 segundos.

Já que se trata de um processamento simples, manteremos como `10`.

E foi assim que surgiram os números de _timeout_ mágicos: `10` (na fila) e `2` (na função).

Configuraremos na `DlqCadastro` o tempo que a mensagem ficará na fila. Ele pode variar entre 1 segundo e 14 dias.

Para isso, adicionaremos abaixo da linha `SqsManagedSseEnabled` a propriedade `MessageRetentionPeriod`, que receberá o valor de `86400`, correspondente ao valor de um dia em segundos.

```yaml
DlqCadastro:
  Type: AWS::SQS::Queue
  Properties:
    QueueName: cadastro-dlq.fifo
    FifoQueue: true
    SqsManagedSseEnabled: false
    MessageRetentionPeriod: 86400
```

Caso uma mensagem seja direcionada para a DLQ, teremos um dia para inspecioná-la antes de ser deletada. Esta é a última configuração que faremos neste momento.

Vamos voltar à janela do terminal e reaizar o _deploy_ na pasta "serverless".

```lua
sls deploy --stage=prod
```

Enquanto aguardamos a conclusão desse processo, vamos lembrar que, _**quando utilizamos o Serverless, é ele que realiza automaticamente o gerenciamento de mensagens da fila**_, recolhendo e deletando mensagens da fila. Isso é muito importante.

Se utilizarmos o SQS fora do ambiente do Serverless, precisaremos usar manualmente os métodos das bibliotecas da AWS para realizar esse gerenciamento dentro da própria aplicação. Vamos disponibilizar a documentação desses métodos nas atividades desta aula.

A seguir, faremos os testes e verificaremos o que fazer com as mensagens transferidas para a DLQ.