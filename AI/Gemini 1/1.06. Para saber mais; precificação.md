Os modelos Gemini, como o 1.0 Pro e o 1.5 Pro, oferecem recursos poderosos para processamento de linguagem natural, mas é importante entender como funciona a precificação para utilizar esses modelos no AI Studio.

## Modelo baseado em uso

O Google AI Studio adota um modelo de precificação baseado no uso, o que significa que você paga apenas pelo que utiliza. O custo é calculado com base na quantidade de tokens processados pelos modelos. Tokens são as unidades básicas de texto, como palavras ou partes de palavras, que são processadas pelos modelos de linguagem.

## Fatores que influenciam o custo

- **Modelo escolhido:** Os diferentes modelos Gemini possuem custos variados por token. Geralmente, modelos mais avançados, como o 1.5 Pro, têm um custo por token maior do que modelos como o 1.0 Pro;
    
- **Quantidade de texto processado:** Quanto mais texto você processar com o modelo, maior será o custo. Isso inclui tanto o texto de entrada (_prompts_) quanto o texto de saída gerado pelo modelo;
    
- **Tipo de tarefa:** Algumas tarefas, como tradução ou geração de código, podem ter um custo por token maior do que tarefas mais simples, como resumo de texto.
    

## Controle de gastos

O AI Studio oferece ferramentas para estimar os custos antes de executar suas tarefas. Você pode verificar o custo por token de cada modelo e calcular o custo aproximado com base na quantidade de texto que pretende processar. Além disso, o AI Studio permite definir orçamentos e alertas para controlar seus gastos. Isso ajuda a evitar surpresas e garante que você utilize os modelos Gemini dentro do seu orçamento previsto.

O custo por token pode variar ao longo do tempo, pois o Google pode ajustar os preços dos modelos Gemini de acordo com atualizações, melhorias ou mudanças na demanda. Além do custo por token, podem haver outros custos associados ao uso do AI Studio, como custos de armazenamento de dados ou uso de outros recursos da plataforma Google Cloud.